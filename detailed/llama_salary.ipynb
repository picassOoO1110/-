{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7070ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8676dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from local\n",
    "model_name = \"/root/autodl-tmp/llama-3.2-1b-instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4d269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    if pd.isna(raw_html):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    return soup.get_text(separator=\" \", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb49c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/root/autodl-tmp/data/salary_labelled_development_set.csv\")  \n",
    "\n",
    "def row_to_text(row, include_label=True):\n",
    "    job_title = row[\"job_title\"]\n",
    "    job_details = clean_html(row[\"job_ad_details\"])\n",
    "    # job_details = row[\"job_ad_details\"]\n",
    "    location = row[\"nation_short_desc\"]\n",
    "\n",
    "    base_text = f\"Job Title: {job_title}\\nJob Description: {job_details}\\nLocation: {location}\"\n",
    "    if include_label:\n",
    "        base_text += f\"\\ny_true: {row['y_true']}\"\n",
    "    return base_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e39b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use first 10 data in train set as few-shot\n",
    "shots = \"\\n\\n\".join([f\"example{i+1}：\\n{row_to_text(train_df.iloc[i])}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4616d54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100,save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n",
      "200,save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n",
      "300,save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n",
      "400,save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n",
      "500,save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/root/autodl-tmp/data/salary_labelled_test_set.csv\")\n",
    "\n",
    "\n",
    "test_df[\"predicted\"] = \"\"\n",
    "test_df[\"true_label\"] = test_df[\"y_true\"].astype(str)\n",
    "results = []\n",
    "correct=0\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    query = f\"query：\\n{row_to_text(row, include_label=False)}\\nyour_predict：y_true =\"\n",
    "\n",
    "    user_prompt = (\n",
    "        \"You are a classification assistant. Below are some job descriptions along with their corresponding salaries (y_true)：\\n\\n\"\n",
    "        \"Please only give me answer, no more other things.The stuctrue shold be like 100-200-AUS-MONTHLY.(No commas are required between numbers)\"\n",
    "        \"If you think there is no mention of salary, please give me 0-0-None-None.\"\n",
    "        \"Do not give me things like y_true = 0-0-None-None, only give me answer, like 0-0-None-None\"\n",
    "        # f\"{shots}\\n\\n{query}\"\n",
    "        f\"{query}\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=30,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    gen_ids = outputs[0][model_inputs[\"input_ids\"].shape[-1]:]\n",
    "    prediction = tokenizer.decode(gen_ids, skip_special_tokens=True).strip().split(\"\\n\")[0]\n",
    "\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"predicted\": prediction,\n",
    "        \"true_label\": str(row[\"y_true\"])\n",
    "    })\n",
    "    if prediction == str(row[\"y_true\"]):\n",
    "        correct+=1\n",
    "    # save\n",
    "    if (i + 1) % 100 == 0:\n",
    "        checkpoint_df = pd.DataFrame(results)\n",
    "        filename = f\"llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\"\n",
    "        checkpoint_df.to_csv(filename, index=False)\n",
    "        print(f\"{i+1},save result to：{filename}\")\n",
    "    number=i\n",
    "    # if i ==220:\n",
    "    #     break\n",
    "\n",
    "\n",
    "filename = f\"llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\"\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c07cd4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ffe43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37101be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=correct/number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce138dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy：16.78%\n",
      "save result to：llama/llama-1b-salary_predictions_nohtml_zeroshot.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy：{accuracy:.2%}\")\n",
    "print(f\"save result to：{filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
